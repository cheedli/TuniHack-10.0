{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok flask requests ffmpeg-python tqdm opencv-python moviepy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sUmSgb9ZHJE",
        "outputId": "74942cf9-e404-4810-9a8d-1c559e55be3f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2024.12.14)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.36.1)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.5.1)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from imageio_ffmpeg>=0.2.0->moviepy) (75.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyngrok, ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0 pyngrok-7.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_itrBs1YgilV",
        "outputId": "c587bced-4e06-46e5-c1b3-054127a3369f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok config add-authtoken 2rJRJd3ZKxaKwd88acgbWZvJKkc_2hicri7WRLoLwBw9KmA47"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch==1.13.1 torchvision==0.14.1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1MxjJkZMUTS",
        "outputId": "3df58ed9-af1e-4204-e834-3f40335a4389"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.13.1\n",
            "  Using cached torch-1.13.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.2.1, 0.2.2, 0.2.2.post2, 0.2.2.post3, 0.15.0\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchvision==0.14.1 (from versions: 0.15.1, 0.15.2, 0.16.0, 0.16.1, 0.16.2, 0.17.0, 0.17.1, 0.17.2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 0.20.0, 0.20.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torchvision==0.14.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install urllib3 --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErAC_-bKQAxw",
        "outputId": "ed4883cb-63de-444e-9007-c10d3cc9e4b2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (2.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show torch torchvision\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OopOmUDfMPRp",
        "outputId": "f5dc1ee9-5cd3-4036-b17e-7cbdd2c94d0a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: torch\n",
            "Version: 2.5.1+cu121\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3-Clause\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu12, nvidia-cuda-cupti-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-curand-cu12, nvidia-cusolver-cu12, nvidia-cusparse-cu12, nvidia-nccl-cu12, nvidia-nvtx-cu12, sympy, triton, typing-extensions\n",
            "Required-by: accelerate, fastai, peft, sentence-transformers, timm, torchaudio, torchvision\n",
            "---\n",
            "Name: torchvision\n",
            "Version: 0.20.1+cu121\n",
            "Summary: image and video datasets and models for torch deep learning\n",
            "Home-page: https://github.com/pytorch/vision\n",
            "Author: PyTorch Core Team\n",
            "Author-email: soumith@pytorch.org\n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: numpy, pillow, torch\n",
            "Required-by: fastai, timm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLnJU2Gtee9d",
        "outputId": "e8e171df-1c07-4f05-ad32-90f4a740bd6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2024.12.14)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.36.1)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.5.1)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from imageio_ffmpeg>=0.2.0->moviepy) (75.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Wav2Lip-GFPGAN'...\n",
            "remote: Enumerating objects: 195, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 195 (delta 18), reused 9 (delta 9), pack-reused 160 (from 1)\u001b[K\n",
            "Receiving objects: 100% (195/195), 29.94 MiB | 40.71 MiB/s, done.\n",
            "Resolving deltas: 100% (39/39), done.\n",
            "--2025-01-19 02:30:27--  https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\n",
            "Resolving www.adrianbulat.com (www.adrianbulat.com)... 45.136.29.207\n",
            "Connecting to www.adrianbulat.com (www.adrianbulat.com)|45.136.29.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 89843225 (86M) [application/octet-stream]\n",
            "Saving to: ‘/content/Wav2Lip-GFPGAN/Wav2Lip-master/face_detection/detection/sfd/s3fd.pth’\n",
            "\n",
            "/content/Wav2Lip-GF 100%[===================>]  85.68M  20.6MB/s    in 4.9s    \n",
            "\n",
            "2025-01-19 02:30:33 (17.3 MB/s) - ‘/content/Wav2Lip-GFPGAN/Wav2Lip-master/face_detection/detection/sfd/s3fd.pth’ saved [89843225/89843225]\n",
            "\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1fQtBSYEyuai9MjBOF8j7zZ4oQ9W2N64q\n",
            "From (redirected): https://drive.google.com/uc?id=1fQtBSYEyuai9MjBOF8j7zZ4oQ9W2N64q&confirm=t&uuid=39acaa49-96de-4f21-a3a6-bd0f10963d76\n",
            "To: /content/Wav2Lip-GFPGAN/Wav2Lip-master/checkpoints/wav2lip.pth\n",
            "100% 436M/436M [00:07<00:00, 54.7MB/s]\n",
            "/content/Wav2Lip-GFPGAN\n",
            "Collecting librosa==0.10.0 (from -r requirements.txt (line 1))\n",
            "  Downloading librosa-0.10.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting numpy<1.24.1 (from -r requirements.txt (line 2))\n",
            "  Downloading numpy-1.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: opencv-contrib-python>=4.2.0.34 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (4.10.0.84)\n",
            "Collecting opencv-python==4.7.0.72 (from -r requirements.txt (line 4))\n",
            "  Downloading opencv_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.20.1+cu121)\n",
            "Collecting tqdm==4.48 (from -r requirements.txt (line 7))\n",
            "  Downloading tqdm-4.48.0-py2.py3-none-any.whl.metadata (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.7/53.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numba==0.56.4 (from -r requirements.txt (line 8))\n",
            "  Downloading numba-0.56.4.tar.gz (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Ngrok Tunnel URL: NgrokTunnel: \"https://78c0-34-19-62-186.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# wav2lip_colab_server.py\n",
        "# -----------------------------------------\n",
        "# 1) Installs pyngrok & other libs\n",
        "# 2) Clones & sets up your EXACT Wav2Lip-GFPGAN pipeline\n",
        "# 3) Fixes the requirement \"torchvision>=>=0.8.2\" using sed\n",
        "# 4) Runs a Flask server with pyngrok on port 5000\n",
        "# 5) Accepts POST /generate-lipsync => returns final video\n",
        "\n",
        "!pip install pyngrok flask requests ffmpeg-python tqdm opencv-python moviepy\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import ffmpeg\n",
        "import requests\n",
        "import shutil\n",
        "import moviepy.editor as mpe\n",
        "from tqdm import tqdm\n",
        "from flask import Flask, request, send_file, jsonify\n",
        "from pyngrok import ngrok\n",
        "\n",
        "################################################################################\n",
        "# (A) Clone Wav2Lip-GFPGAN, fix requirements, download weights\n",
        "################################################################################\n",
        "!git clone https://github.com/ajay-sainy/Wav2Lip-GFPGAN.git\n",
        "basePath = \"/content/Wav2Lip-GFPGAN\"\n",
        "\n",
        "wav2lipFolderName = \"Wav2Lip-master\"\n",
        "gfpganFolderName  = \"GFPGAN-master\"\n",
        "\n",
        "wav2lipPath = os.path.join(basePath, wav2lipFolderName)\n",
        "gfpganPath  = os.path.join(basePath, gfpganFolderName)\n",
        "\n",
        "# Download s3fd.pth\n",
        "!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" \\\n",
        "     -O \"{wav2lipPath}/face_detection/detection/sfd/s3fd.pth\"\n",
        "\n",
        "# Download checkpoints (wav2lip.pth)\n",
        "!gdown https://drive.google.com/uc?id=1fQtBSYEyuai9MjBOF8j7zZ4oQ9W2N64q \\\n",
        "       --output \"{wav2lipPath}/checkpoints/wav2lip.pth\"\n",
        "\n",
        "# Move into Wav2Lip-GFPGAN folder\n",
        "%cd \"{basePath}\"\n",
        "\n",
        "# --- FIX the \"torchvision>=>=0.8.2\" line if present ---\n",
        "!sed -i 's/torchvision>=>=0.8.2/torchvision>=0.8.2/' requirements.txt\n",
        "\n",
        "# Install the patched requirements\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# Create inputs/outputs folders if missing\n",
        "inputsPath  = os.path.join(basePath, \"inputs\")\n",
        "outputsPath = os.path.join(basePath, \"outputs\")\n",
        "os.makedirs(inputsPath, exist_ok=True)\n",
        "os.makedirs(outputsPath, exist_ok=True)\n",
        "\n",
        "################################################################################\n",
        "# (B) Flask server with pyngrok\n",
        "################################################################################\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def index():\n",
        "    return \"Colab Wav2Lip + GFPGAN server is running with pyngrok!\"\n",
        "\n",
        "@app.route(\"/generate-lipsync\", methods=[\"POST\"])\n",
        "def generate_lipsync():\n",
        "    \"\"\"\n",
        "    1) Receives:\n",
        "       - audio (MP3)\n",
        "       - video (MP4)\n",
        "       - subtitles (SRT) [optional]\n",
        "    2) Runs your EXACT Wav2Lip pipeline for lip-syncing with GFPGAN enhancements.\n",
        "    3) Merges audio at the end, then optionally merges subtitles.\n",
        "    4) Returns final MP4 to the client.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1) Save incoming files\n",
        "        audio_file = request.files.get(\"audio\")\n",
        "        video_file = request.files.get(\"video\")\n",
        "        srt_file   = request.files.get(\"subtitles\")\n",
        "\n",
        "        if not audio_file or not video_file:\n",
        "            return jsonify({\"error\": \"Missing audio or video file\"}), 400\n",
        "\n",
        "        # Clear old inputs/outputs\n",
        "        if os.path.exists(inputsPath):\n",
        "            shutil.rmtree(inputsPath)\n",
        "        if os.path.exists(outputsPath):\n",
        "            shutil.rmtree(outputsPath)\n",
        "        os.makedirs(inputsPath, exist_ok=True)\n",
        "        os.makedirs(outputsPath, exist_ok=True)\n",
        "\n",
        "        inputAudioPath = os.path.join(inputsPath, \"output.mp3\")\n",
        "        inputVideoPath = os.path.join(inputsPath, \"video.mp4\")\n",
        "\n",
        "        with open(inputAudioPath, \"wb\") as f:\n",
        "            f.write(audio_file.read())\n",
        "        with open(inputVideoPath, \"wb\") as f:\n",
        "            f.write(video_file.read())\n",
        "\n",
        "        srtPath = None\n",
        "        if srt_file:\n",
        "            # Put subtitles in \"subtitles\" folder\n",
        "            subsDir = os.path.join(basePath, \"subtitles\")\n",
        "            if os.path.exists(subsDir):\n",
        "                shutil.rmtree(subsDir)\n",
        "            os.makedirs(subsDir, exist_ok=True)\n",
        "            srtPath = os.path.join(subsDir, \"transcript.srt\")\n",
        "            with open(srtPath, \"wb\") as f:\n",
        "                f.write(srt_file.read())\n",
        "\n",
        "        # 2) Wav2Lip inference\n",
        "        # cd into Wav2Lip folder, run inference.py\n",
        "        lipSyncedOutputPath = os.path.join(outputsPath, \"result.mp4\")\n",
        "\n",
        "        %cd \"{wav2lipPath}\"\n",
        "        !python inference.py \\\n",
        "            --checkpoint_path checkpoints/wav2lip.pth \\\n",
        "            --face \"{inputVideoPath}\" \\\n",
        "            --audio \"{inputAudioPath}\" \\\n",
        "            --outfile \"{lipSyncedOutputPath}\"\n",
        "\n",
        "        # 3) GFPGAN setup & run\n",
        "        %cd \"{gfpganPath}\"\n",
        "        !python setup.py develop\n",
        "        !wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth \\\n",
        "            -P experiments/pretrained_models\n",
        "\n",
        "        # We'll restore frames from `result.mp4`\n",
        "        import cv2\n",
        "        import numpy as np\n",
        "        from os import path\n",
        "\n",
        "        inputVideoPath2 = lipSyncedOutputPath\n",
        "        unProcessedFramesFolderPath = os.path.join(outputsPath, \"frames\")\n",
        "        os.makedirs(unProcessedFramesFolderPath, exist_ok=True)\n",
        "\n",
        "        vidcap = cv2.VideoCapture(inputVideoPath2)\n",
        "        numberOfFrames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
        "        print(\"FPS:\", fps, \"Frames:\", numberOfFrames)\n",
        "\n",
        "        for frameNum in tqdm(range(numberOfFrames)):\n",
        "            success, image = vidcap.read()\n",
        "            if not success:\n",
        "                break\n",
        "            cv2.imwrite(\n",
        "                path.join(unProcessedFramesFolderPath, f\"{frameNum:04d}.jpg\"),\n",
        "                image\n",
        "            )\n",
        "\n",
        "        # Possibly upgrade torchvision if needed\n",
        "        !pip install --upgrade torchvision\n",
        "\n",
        "        # GFPGAN inference\n",
        "        !python inference_gfpgan.py \\\n",
        "          -i \"{unProcessedFramesFolderPath}\" \\\n",
        "          -o \"{outputsPath}\" \\\n",
        "          -v 1.3 -s 2 --only_center_face --bg_upsampler None\n",
        "\n",
        "        # Reassemble frames in batches of 300\n",
        "        restoredFramesPath = os.path.join(outputsPath, \"restored_imgs\")\n",
        "        dir_list = sorted(os.listdir(restoredFramesPath))\n",
        "        batch = 0\n",
        "        batchSize = 300\n",
        "\n",
        "        for i in tqdm(range(0, len(dir_list), batchSize)):\n",
        "            img_array = []\n",
        "            start, end = i, i + batchSize\n",
        "            print(\"processing\", start, end)\n",
        "\n",
        "            for filename in dir_list[start:end]:\n",
        "                filepath = os.path.join(restoredFramesPath, filename)\n",
        "                img = cv2.imread(filepath)\n",
        "                if img is None:\n",
        "                    continue\n",
        "                height, width, layers = img.shape\n",
        "                size = (width, height)\n",
        "                img_array.append(img)\n",
        "\n",
        "            outPath = os.path.join(outputsPath, f\"batch_{batch:04d}.avi\")\n",
        "            out = cv2.VideoWriter(outPath, cv2.VideoWriter_fourcc(*'DIVX'), 30, size)\n",
        "            batch += 1\n",
        "\n",
        "            for frame in img_array:\n",
        "                out.write(frame)\n",
        "            out.release()\n",
        "\n",
        "        # concat the batch AVIs\n",
        "        concatTextFilePath = os.path.join(outputsPath, \"concat.txt\")\n",
        "        with open(concatTextFilePath, \"w\") as ctf:\n",
        "            for idx in range(batch):\n",
        "                ctf.write(f\"file batch_{idx:04d}.avi\\n\")\n",
        "\n",
        "        concatedVideoOutputPath = os.path.join(outputsPath, \"concated_output.avi\")\n",
        "        !ffmpeg -y -f concat -i \"{concatTextFilePath}\" -c copy \"{concatedVideoOutputPath}\"\n",
        "\n",
        "        finalProcessedOutputVideo = os.path.join(outputsPath, \"final_with_audio.avi\")\n",
        "        !ffmpeg -y -i \"{concatedVideoOutputPath}\" -i \"{inputAudioPath}\" \\\n",
        "                 -map 0 -map 1:a -c:v copy -shortest \"{finalProcessedOutputVideo}\"\n",
        "\n",
        "        # 4) Merge subtitles if provided\n",
        "        final_no_subs = os.path.join(outputsPath, \"final_no_subs.mp4\")\n",
        "        !ffmpeg -y -i \"{finalProcessedOutputVideo}\" -c copy \"{final_no_subs}\"\n",
        "\n",
        "        final_with_subs = os.path.join(outputsPath, \"final_with_subs.mp4\")\n",
        "        if srtPath and os.path.exists(srtPath):\n",
        "            (\n",
        "                ffmpeg\n",
        "                .input(final_no_subs)\n",
        "                .output(final_with_subs, vf=f\"subtitles={srtPath}\", strict='experimental')\n",
        "                .run(overwrite_output=True)\n",
        "            )\n",
        "            outputToReturn = final_with_subs\n",
        "        else:\n",
        "            outputToReturn = final_no_subs\n",
        "\n",
        "        print(f\"Returning file: {outputToReturn}\")\n",
        "        return send_file(outputToReturn, as_attachment=True)\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "# (C) Create the ngrok tunnel on port 5000\n",
        "public_url = ngrok.connect(5000)\n",
        "print(\"Ngrok Tunnel URL:\", public_url)\n",
        "\n",
        "# (D) Run the Flask server\n",
        "app.run(host='0.0.0.0', port=5000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cIF8sFT1wOI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}